['fullModel.py', '--dataroot', '/scratch/user/jiangziyu/train/', '--learn_residual', '--resize_or_crop', 'scale_width', '--fineSize', '256', '--batchSize', '1', '--name', 'fullModel']
------------ Options -------------
batchSize: 1
beta1: 0.5
checkpoints_dir: ./checkpoints
continue_train: False
dataroot: /scratch/user/jiangziyu/train/
dataset_mode: aligned
display_freq: 100
display_id: 1
display_port: 8097
display_single_pane_ncols: 0
display_winsize: 256
epoch_count: 1
fineSize: 256
gan_type: wgan-gp
gpu_ids: [0]
identity: 0.0
input_nc: 3
isTrain: True
lambda_A: 100.0
lambda_B: 10.0
learn_residual: True
loadSizeX: 640
loadSizeY: 360
lr: 0.0001
max_dataset_size: inf
model: content_gan
nThreads: 2
n_layers_D: 3
name: fullModel
ndf: 64
ngf: 64
niter: 150
niter_decay: 150
no_dropout: False
no_flip: False
no_html: False
norm: instance
output_nc: 3
phase: train
pool_size: 50
print_freq: 100
resize_or_crop: scale_width
save_epoch_freq: 5
save_latest_freq: 5000
serial_batches: False
which_direction: AtoB
which_epoch: latest
which_model_netD: basic
which_model_netG: resnet_9blocks
-------------- End ----------------
------- Networks deblur_G initialized ---------
ResnetGenerator(
  (model): Sequential(
    (0): ReflectionPad2d((3, 3, 3, 3))
    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))
    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)
    (3): ReLU(inplace)
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)
    (6): ReLU(inplace)
    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
    (9): ReLU(inplace)
    (10): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (11): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (12): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (13): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (14): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (15): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (16): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (17): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (18): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)
    (21): ReLU(inplace)
    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)
    (24): ReLU(inplace)
    (25): ReflectionPad2d((3, 3, 3, 3))
    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))
    (27): Tanh()
  )
)
Total number of parameters: 11378179
-----------------------------------------------
more than 1 GPU detected...
(epoch 0 itr 20) unsupervised loss is 0.029178
(epoch 0 itr 40) unsupervised loss is 0.014285
(epoch 0 itr 60) unsupervised loss is 0.011461
(epoch 0 itr 80) unsupervised loss is 0.009148
(epoch 0 itr 100) unsupervised loss is 0.013126
(epoch 0 itr 120) unsupervised loss is 0.013837
(epoch 0 itr 140) unsupervised loss is 0.010257
(epoch 0 itr 160) unsupervised loss is 0.008643
(epoch 0 itr 180) unsupervised loss is 0.007693
(epoch 0 itr 200) unsupervised loss is 0.008229
(epoch 0 itr 220) unsupervised loss is 0.007567
(epoch 0 itr 240) unsupervised loss is 0.008410
(epoch 0 itr 260) unsupervised loss is 0.008173
(epoch 0 itr 280) unsupervised loss is 0.012084
(epoch 0 itr 300) unsupervised loss is 0.007338
(epoch 0 itr 320) unsupervised loss is 0.006811
(epoch 0 itr 340) unsupervised loss is 0.007548
(epoch 0 itr 360) unsupervised loss is 0.006686
(epoch 0 itr 380) unsupervised loss is 0.006506
(epoch 0 itr 400) unsupervised loss is 0.005678
(epoch 0 itr 420) unsupervised loss is 0.006470
(epoch 0 itr 440) unsupervised loss is 0.006428
(epoch 0 itr 460) unsupervised loss is 0.006569
(epoch 0 itr 480) unsupervised loss is 0.005963
(epoch 0 itr 500) unsupervised loss is 0.005476
(epoch 0 itr 520) unsupervised loss is 0.005563
(epoch 0 itr 540) unsupervised loss is 0.006543
(epoch 0 itr 560) unsupervised loss is 0.005260
(epoch 0 itr 580) unsupervised loss is 0.005849
(epoch 0 itr 600) unsupervised loss is 0.004584
(epoch 0 itr 620) unsupervised loss is 0.005673
(epoch 0 itr 640) unsupervised loss is 0.007119
(epoch 0 itr 660) unsupervised loss is 0.005988
(epoch 0 itr 680) unsupervised loss is 0.004905
(epoch 0 itr 700) unsupervised loss is 0.004530
(epoch 0 itr 720) unsupervised loss is 0.004686
(epoch 0 itr 740) unsupervised loss is 0.006793
(epoch 0 itr 760) unsupervised loss is 0.004614
(epoch 0 itr 780) unsupervised loss is 0.005952
(epoch 0 itr 800) unsupervised loss is 0.009400
(epoch 0 itr 820) unsupervised loss is 0.005938
(epoch 0 itr 840) unsupervised loss is 0.005114
(epoch 0 itr 860) unsupervised loss is 0.004649
(epoch 0 itr 880) unsupervised loss is 0.004702
(epoch 0 itr 900) unsupervised loss is 0.004357
(epoch 0 itr 920) unsupervised loss is 0.004650
(epoch 0 itr 940) unsupervised loss is 0.005040
(epoch 0 itr 960) unsupervised loss is 0.004523
(epoch 0 itr 980) unsupervised loss is 0.005022
(epoch 0 itr 1000) unsupervised loss is 0.005846
(epoch 0 itr 1020) unsupervised loss is 0.006950
(epoch 0 itr 1040) unsupervised loss is 0.004992
(epoch 0 itr 1060) unsupervised loss is 0.004580
(epoch 0 itr 1080) unsupervised loss is 0.004963
(epoch 0 itr 1100) unsupervised loss is 0.004604
(epoch 0 itr 1120) unsupervised loss is 0.004756
(epoch 0 itr 1140) unsupervised loss is 0.006105
(epoch 0 itr 1160) unsupervised loss is 0.004393
(epoch 0 itr 1180) unsupervised loss is 0.003830
(epoch 0 itr 1200) unsupervised loss is 0.004671
(epoch 0 itr 1220) unsupervised loss is 0.004547
(epoch 0 itr 1240) unsupervised loss is 0.004054
(epoch 0 itr 1260) unsupervised loss is 0.004823
(epoch 0 itr 1280) unsupervised loss is 0.005719
(epoch 0 itr 1300) unsupervised loss is 0.004273
(epoch 0 itr 1320) unsupervised loss is 0.005183
(epoch 0 itr 1340) unsupervised loss is 0.005948
(epoch 0 itr 1360) unsupervised loss is 0.003911
(epoch 0 itr 1380) unsupervised loss is 0.003974
(epoch 0 itr 1400) unsupervised loss is 0.004711
(epoch 0 itr 1420) unsupervised loss is 0.004075
(epoch 0 itr 1440) unsupervised loss is 0.004900
(epoch 0 itr 1460) unsupervised loss is 0.004575
(epoch 0 itr 1480) unsupervised loss is 0.004102
(epoch 0 itr 1500) unsupervised loss is 0.004148
(epoch 0 itr 1520) unsupervised loss is 0.004068
(epoch 0 itr 1540) unsupervised loss is 0.004232
(epoch 0 itr 1560) unsupervised loss is 0.003593
(epoch 0 itr 1580) unsupervised loss is 0.006342
(epoch 0 itr 1600) unsupervised loss is 0.003944
(epoch 0 itr 1620) unsupervised loss is 0.004084
(epoch 0 itr 1640) unsupervised loss is 0.004778
(epoch 0 itr 1660) unsupervised loss is 0.004991
(epoch 0 itr 1680) unsupervised loss is 0.003950
(epoch 0 itr 1700) unsupervised loss is 0.004276
(epoch 0 itr 1720) unsupervised loss is 0.003643
(epoch 0 itr 1740) unsupervised loss is 0.004548
(epoch 0 itr 1760) unsupervised loss is 0.003795
(epoch 0 itr 1780) unsupervised loss is 0.004855
(epoch 0 itr 1800) unsupervised loss is 0.003741
(epoch 0 itr 1820) unsupervised loss is 0.004978
(epoch 0 itr 1840) unsupervised loss is 0.003717
(epoch 0 itr 1860) unsupervised loss is 0.004151
(epoch 0 itr 1880) unsupervised loss is 0.004195
(epoch 0 itr 1900) unsupervised loss is 0.004231
(epoch 0 itr 1920) unsupervised loss is 0.003652
(epoch 0 itr 1940) unsupervised loss is 0.004058
(epoch 0 itr 1960) unsupervised loss is 0.006069
(epoch 0 itr 1980) unsupervised loss is 0.003492
(epoch 0 itr 2000) unsupervised loss is 0.005243
(epoch 0 itr 2020) unsupervised loss is 0.003866
(epoch 0 itr 2040) unsupervised loss is 0.005027
(epoch 1 itr 20) unsupervised loss is 0.004001
(epoch 1 itr 40) unsupervised loss is 0.003766
(epoch 1 itr 60) unsupervised loss is 0.003656
(epoch 1 itr 80) unsupervised loss is 0.004198
(epoch 1 itr 100) unsupervised loss is 0.003552
(epoch 1 itr 120) unsupervised loss is 0.003601
(epoch 1 itr 140) unsupervised loss is 0.003387
(epoch 1 itr 160) unsupervised loss is 0.004200
(epoch 1 itr 180) unsupervised loss is 0.003733
(epoch 1 itr 200) unsupervised loss is 0.003471
(epoch 1 itr 220) unsupervised loss is 0.002919
(epoch 1 itr 240) unsupervised loss is 0.003579
(epoch 1 itr 260) unsupervised loss is 0.004142
(epoch 1 itr 280) unsupervised loss is 0.004066
(epoch 1 itr 300) unsupervised loss is 0.003856
(epoch 1 itr 320) unsupervised loss is 0.003423
(epoch 1 itr 340) unsupervised loss is 0.004594
(epoch 1 itr 360) unsupervised loss is 0.003683
(epoch 1 itr 380) unsupervised loss is 0.003497
(epoch 1 itr 400) unsupervised loss is 0.004773
(epoch 1 itr 420) unsupervised loss is 0.003291
(epoch 1 itr 440) unsupervised loss is 0.003492
(epoch 1 itr 460) unsupervised loss is 0.003667
(epoch 1 itr 480) unsupervised loss is 0.003178
(epoch 1 itr 500) unsupervised loss is 0.003313
(epoch 1 itr 520) unsupervised loss is 0.004676
(epoch 1 itr 540) unsupervised loss is 0.003793
(epoch 1 itr 560) unsupervised loss is 0.003967
(epoch 1 itr 580) unsupervised loss is 0.003791
(epoch 1 itr 600) unsupervised loss is 0.004222
(epoch 1 itr 620) unsupervised loss is 0.003566
(epoch 1 itr 640) unsupervised loss is 0.003459
(epoch 1 itr 660) unsupervised loss is 0.003713
(epoch 1 itr 680) unsupervised loss is 0.003704
(epoch 1 itr 700) unsupervised loss is 0.004159
(epoch 1 itr 720) unsupervised loss is 0.003657
(epoch 1 itr 740) unsupervised loss is 0.003208
(epoch 1 itr 760) unsupervised loss is 0.003367
(epoch 1 itr 780) unsupervised loss is 0.003673
(epoch 1 itr 800) unsupervised loss is 0.003214
(epoch 1 itr 820) unsupervised loss is 0.003567
(epoch 1 itr 840) unsupervised loss is 0.003111
(epoch 1 itr 860) unsupervised loss is 0.004530
(epoch 1 itr 880) unsupervised loss is 0.003591
(epoch 1 itr 900) unsupervised loss is 0.005843
(epoch 1 itr 920) unsupervised loss is 0.003470
(epoch 1 itr 940) unsupervised loss is 0.003346
(epoch 1 itr 960) unsupervised loss is 0.004623
(epoch 1 itr 980) unsupervised loss is 0.003651
(epoch 1 itr 1000) unsupervised loss is 0.003635
(epoch 1 itr 1020) unsupervised loss is 0.003337
(epoch 1 itr 1040) unsupervised loss is 0.004532
(epoch 1 itr 1060) unsupervised loss is 0.004137
(epoch 1 itr 1080) unsupervised loss is 0.003265
(epoch 1 itr 1100) unsupervised loss is 0.003302
(epoch 1 itr 1120) unsupervised loss is 0.003442
(epoch 1 itr 1140) unsupervised loss is 0.003626
(epoch 1 itr 1160) unsupervised loss is 0.003375
(epoch 1 itr 1180) unsupervised loss is 0.003321
(epoch 1 itr 1200) unsupervised loss is 0.004927
(epoch 1 itr 1220) unsupervised loss is 0.003452
(epoch 1 itr 1240) unsupervised loss is 0.003930
(epoch 1 itr 1260) unsupervised loss is 0.003224
(epoch 1 itr 1280) unsupervised loss is 0.004579
(epoch 1 itr 1300) unsupervised loss is 0.003427
(epoch 1 itr 1320) unsupervised loss is 0.003920
(epoch 1 itr 1340) unsupervised loss is 0.003640
(epoch 1 itr 1360) unsupervised loss is 0.003123
(epoch 1 itr 1380) unsupervised loss is 0.003635
(epoch 1 itr 1400) unsupervised loss is 0.003355
(epoch 1 itr 1420) unsupervised loss is 0.003150
(epoch 1 itr 1440) unsupervised loss is 0.003067
(epoch 1 itr 1460) unsupervised loss is 0.003077
(epoch 1 itr 1480) unsupervised loss is 0.004598
(epoch 1 itr 1500) unsupervised loss is 0.004057
(epoch 1 itr 1520) unsupervised loss is 0.003569
(epoch 1 itr 1540) unsupervised loss is 0.004379
(epoch 1 itr 1560) unsupervised loss is 0.003584
(epoch 1 itr 1580) unsupervised loss is 0.003818
(epoch 1 itr 1600) unsupervised loss is 0.003773
(epoch 1 itr 1620) unsupervised loss is 0.002833
(epoch 1 itr 1640) unsupervised loss is 0.003499
(epoch 1 itr 1660) unsupervised loss is 0.003649
(epoch 1 itr 1680) unsupervised loss is 0.003443
(epoch 1 itr 1700) unsupervised loss is 0.003269
(epoch 1 itr 1720) unsupervised loss is 0.004349
(epoch 1 itr 1740) unsupervised loss is 0.004602
(epoch 1 itr 1760) unsupervised loss is 0.003648
(epoch 1 itr 1780) unsupervised loss is 0.003199
(epoch 1 itr 1800) unsupervised loss is 0.004181
(epoch 1 itr 1820) unsupervised loss is 0.003166
(epoch 1 itr 1840) unsupervised loss is 0.004101
(epoch 1 itr 1860) unsupervised loss is 0.003993
(epoch 1 itr 1880) unsupervised loss is 0.004147
(epoch 1 itr 1900) unsupervised loss is 0.003625
(epoch 1 itr 1920) unsupervised loss is 0.003634
(epoch 1 itr 1940) unsupervised loss is 0.004316
(epoch 1 itr 1960) unsupervised loss is 0.003662
(epoch 1 itr 1980) unsupervised loss is 0.003524
(epoch 1 itr 2000) unsupervised loss is 0.004121
(epoch 1 itr 2020) unsupervised loss is 0.003026
(epoch 1 itr 2040) unsupervised loss is 0.003948
